{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88f77ed4",
   "metadata": {},
   "source": [
    "# PRELIMINARY TRAINING AND MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f7ddbc",
   "metadata": {},
   "source": [
    "Jack Sparke | 13660507 | 05/11/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e5e77e",
   "metadata": {},
   "source": [
    "# Package and Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9753bea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import random\n",
    "from statistics import mean\n",
    "import time\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.utils import resample\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold,cross_validate\n",
    "from pylab import rcParams\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import glob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, KFold, cross_val_predict\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score, roc_curve, roc_auc_score, confusion_matrix\n",
    "#from sklearn.cross_validation import StratifiedKFold,cross_val_score ## old name\n",
    "from sklearn.model_selection import StratifiedKFold,cross_val_score\n",
    "#from sklearn.cross_validation import train_test_split  # old name\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='sklearn')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9d9e5a",
   "metadata": {},
   "source": [
    "The following was copied over from a set of unorganised python scripts compiled in Spypder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3508d692",
   "metadata": {},
   "source": [
    "# Function Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2affdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing_values(seq):\n",
    "    \"\"\"\n",
    "    Finds the missing values in a sequence of data.\n",
    "    \n",
    "    Parameters:\n",
    "    seq (list): A list of sequential data.\n",
    "    \n",
    "    Returns:\n",
    "    missing_values (list): A list of missing values in the sequence.\n",
    "    \"\"\"\n",
    "    missing_values = []\n",
    "    seq = sorted(seq)\n",
    "    for i in range(seq[0], seq[-1] + 1):\n",
    "        if i not in seq:\n",
    "            missing_values.append(i)\n",
    "    \n",
    "    return missing_values\n",
    "\n",
    "def reduce_sequence(missing_values, df):\n",
    "    \"\"\"\n",
    "    Reduces the sequence to ensure the data is incremental. \n",
    "    Important for XGBoost models.\n",
    "    \n",
    "    Currently hard-coded to suit the project's needs.\n",
    "    \n",
    "    Parameters:\n",
    "    missing_values (list): A list the missing values, found using the find_missing_values function.\n",
    "    df (DataFrame): The dataframe of which to reduce the class values to be incremental.\n",
    "    \n",
    "    Returns:\n",
    "    df_fixed (DataFrame): A DataFrame with the class sequence incrementalised.\n",
    "    \"\"\"\n",
    "    df_func = df.sort_values(by=2)\n",
    "    df_func = df_func.reset_index(drop=True)\n",
    "    index_1 = df_func[df_func[2] == missing_values[0]+1].index[0]\n",
    "    df_1 = df_func[:index_1]\n",
    "\n",
    "    for i in range(0,len(missing_values)):\n",
    "        if i == 0:\n",
    "                    \n",
    "            index_missed = df_func[df_func[2] == missing_values[i]+1].index[0]\n",
    "            df_spliced = df_func[index_missed:]\n",
    "            df_spliced[2] = df_spliced[2] - 1 \n",
    "            df_spliced = df_spliced.reset_index(drop=True)\n",
    "            index_missed = df_spliced[df_spliced[2] == missing_values[i+1]].index[0]\n",
    "            df_spliced = df_spliced[:index_missed]\n",
    "\n",
    "        else:\n",
    "                    \n",
    "            index_missed = df_func[df_func[2] == missing_values[i]].index[0]\n",
    "            \n",
    "            df_spliced2 = df_func[index_missed:]\n",
    "            df_spliced2[2] = df_spliced2[2] - 2 \n",
    "    \n",
    "    df_fixed = pd.concat([df_1,df_spliced, df_spliced2], axis=0)\n",
    "    df_fixed = df_fixed.reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    return df_fixed\n",
    "\n",
    "\n",
    "def combine_df():\n",
    "    \"\"\"\n",
    "    Imports the data from each feature extraction method and merges it row-wise.\n",
    "    \n",
    "    Returns:\n",
    "    combined_df (DataFrame): A DataFrame with each of the datasets merged row-wise.\n",
    "    \"\"\"\n",
    "        filepath_list = [r\"C:\\Users\\jacks\\OneDrive - Bond University\\233\\AML\\ASSIGN 1\\FeatureExtraction_Tchebyshev_Mukundan2014_10Samples_perimage (1).dat\",\n",
    "             r\"C:\\Users\\jacks\\OneDrive - Bond University\\233\\AML\\ASSIGN 1\\FeatureExtraction_BGLBP_10samples_perimage2.dat\",\n",
    "             r\"C:\\Users\\jacks\\OneDrive - Bond University\\233\\AML\\ASSIGN 1\\FeatureExtraction_CSLBP_10samples_perimage2.dat\",\n",
    "             r\"C:\\Users\\jacks\\OneDrive - Bond University\\233\\AML\\ASSIGN 1\\FeatureExtraction_CSSILTP_10samples_perimage2.dat\",\n",
    "             r\"C:\\Users\\jacks\\OneDrive - Bond University\\233\\AML\\ASSIGN 1\\FeatureExtraction_SILTP_10samples_perimage2.dat\",\n",
    "             r\"C:\\Users\\jacks\\OneDrive - Bond University\\233\\AML\\ASSIGN 1\\FeatureExtraction_SCSLBP_10samples_perimage2.dat\",\n",
    "             r\"C:\\Users\\jacks\\OneDrive - Bond University\\233\\AML\\ASSIGN 1\\FeatureExtraction_OLBP_10Samples_perimage2.dat\"\n",
    "             ]\n",
    "\n",
    "\n",
    "    counter =  0\n",
    "    combined_df = None\n",
    "    for path in filepath_list:\n",
    "        df = pd.read_csv(path, header=None)\n",
    "        \n",
    "        if counter > 0:\n",
    "            df = df.iloc[:, 3:]\n",
    "        \n",
    "        if combined_df is None:\n",
    "            combined_df = df\n",
    "        else:\n",
    "            combined_df = pd.concat([combined_df, df], axis=1)\n",
    "        counter += 1\n",
    "        \n",
    "    return combined_df\n",
    "\n",
    "\n",
    "def dfs_in_list():\n",
    "    \"\"\"\n",
    "    Imports each of the data in a list rather than into a merged DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "    df_list (list): A list of each DataFrame.\n",
    "    \"\"\"\n",
    "    filepath_list = [r\"C:\\Users\\jacks\\OneDrive - Bond University\\233\\AML\\ASSIGN 1\\FeatureExtraction_Tchebyshev_Mukundan2014_10Samples_perimage (1).dat\",\n",
    "         r\"C:\\Users\\jacks\\OneDrive - Bond University\\233\\AML\\ASSIGN 1\\FeatureExtraction_BGLBP_10samples_perimage2.dat\",\n",
    "         r\"C:\\Users\\jacks\\OneDrive - Bond University\\233\\AML\\ASSIGN 1\\FeatureExtraction_CSLBP_10samples_perimage2.dat\",\n",
    "         r\"C:\\Users\\jacks\\OneDrive - Bond University\\233\\AML\\ASSIGN 1\\FeatureExtraction_CSSILTP_10samples_perimage2.dat\",\n",
    "         r\"C:\\Users\\jacks\\OneDrive - Bond University\\233\\AML\\ASSIGN 1\\FeatureExtraction_SILTP_10samples_perimage2.dat\",\n",
    "         r\"C:\\Users\\jacks\\OneDrive - Bond University\\233\\AML\\ASSIGN 1\\FeatureExtraction_SCSLBP_10samples_perimage2.dat\",\n",
    "         r\"C:\\Users\\jacks\\OneDrive - Bond University\\233\\AML\\ASSIGN 1\\FeatureExtraction_OLBP_10Samples_perimage2.dat\"\n",
    "         ]\n",
    "    df_list = []\n",
    "    for path in filepath_list:\n",
    "        df = pd.read_csv(path, header=None)\n",
    "        df_list.append(df)\n",
    "        \n",
    "    return df_list\n",
    "        \n",
    "    \n",
    "\n",
    "def attr_name(df, df_name):\n",
    "    \"\"\"\n",
    "    A function for adding interpretable names to the features of the data.\n",
    "    Used when doing feature selection and to filter the data.\n",
    "    \n",
    "    The result feature names will be in the form: feature_extraction_methodCol_number.\n",
    "    E.g., SILTP3, OLBP56, etc.\n",
    "    \n",
    "    Parameters:\n",
    "    l (list): A list of the updated feature names.\n",
    "    \"\"\"\n",
    "    df_fts = df.columns[3:]\n",
    "    l = []\n",
    "    for j in df_fts:\n",
    "        h = df_name + str(j)\n",
    "        l.append(h)\n",
    "    \n",
    "    return l\n",
    "    \n",
    "    \n",
    "def importer(xgboost=0, family=0):\n",
    "    \"\"\"\n",
    "    Import the data to be split into X and y.\n",
    "    \n",
    "    Parameters:\n",
    "    xgboost (int): If 1, removes the missing values in the class variable, and incrementalising this data to be \n",
    "                    prepared for xgboost modeling. Default is 0.\n",
    "    family (int): If 1, the y value returns the family columns instead of the species column. Default is 0.\n",
    "    \n",
    "    Returns:\n",
    "    X (DataFrame): A DataFrame of the input data.\n",
    "    y (Series): A series of the target variable. Depending on the family parameter, either family or species class.\n",
    "    \"\"\"\n",
    "\n",
    "    df_list = dfs_in_list()\n",
    "    comb_df = combine_df()\n",
    "    \n",
    "    if xgboost == 1:\n",
    "        missing_values = find_missing_values(comb_df[2].values)\n",
    "        comb_df = reduce_sequence(missing_values, comb_df)\n",
    "    \n",
    "    \n",
    "    method_names = ['tchebyshev', 'bglbp', 'cslbp', 'cssiltp', 'siltp', 'scslbp', 'olbp']\n",
    "    \n",
    "    att_names = []\n",
    "    \n",
    "    \n",
    "    for i in range(0, len(df_list)):\n",
    "        df = df_list[i]\n",
    "        l = attr_name(df, method_names[i])\n",
    "        att_names.append(l)\n",
    "        \n",
    "    if family==1:\n",
    "        X = comb_df.drop([0,1,2], axis=1)\n",
    "        y = comb_df[0].values\n",
    "    else:\n",
    "        X = comb_df.drop([0,1,2], axis=1)\n",
    "        y = comb_df[2].values\n",
    "    \n",
    "    att_names_ext = []\n",
    "\n",
    "    \n",
    "    for arr in att_names:\n",
    "        att_names_ext.extend(arr)\n",
    "    \n",
    "    X.columns = att_names_ext\n",
    "    \n",
    "    return X, y\n",
    "    \n",
    "def check_class_probabilities(probs):\n",
    "    \"\"\"\n",
    "    Ensures the probabilities generated from a model adds up to one of class-wise basis.\n",
    "    If not, this function normalises the data to do so. \n",
    "    \n",
    "    Parameters:\n",
    "    probs (Array): Array of the probabilties generated from the model. \n",
    "    \"\"\"\n",
    "    row_sums = np.sum(probs, axis=1) \n",
    "\n",
    "    # Find rows where the sum is not close to 1.0 within a tolerance\n",
    "    invalid_rows = np.where(np.abs(row_sums - 1.0) > 1e-6)[0]\n",
    "\n",
    "    if len(invalid_rows) > 0:\n",
    "        print(\"Invalid probabilities found in rows:\", invalid_rows)\n",
    "        \n",
    "        # Normalize the probabilities for the invalid rows\n",
    "        for row_index in invalid_rows:\n",
    "            probs[row_index] /= row_sums[row_index]\n",
    "\n",
    "        print(\"Probabilities have been normalized.\")\n",
    "    else:\n",
    "        print(\"All class probabilities are correctly normalized.\")\n",
    "    \n",
    "        \n",
    "def cross_validate_new(estimator, X, y, cv=4):\n",
    "    \"\"\"\n",
    "    Created cross validation function as the Sci-Kit functions too an extensive amount of time.\n",
    "    Uses the StratifiedKFold function from Sci-Kit to ensure the existence of each class in each fold. \n",
    "    \n",
    "    If the model does not predict at least one of each species, the function is stopped immediately. \n",
    "    \n",
    "    Parameters:\n",
    "    estimator (object): Machine learning model that has the fit, predict and predict_proba methods.\n",
    "    X (Series): Input data to be used to fit the model.\n",
    "    y (Array): Class data to be used to fit the model.\n",
    "    cv (int): Number of folds. Default is 4.\n",
    "    \n",
    "    Returns:\n",
    "    X (DataFrame): The fitted estimator from the last fold. \n",
    "    cv_dict (Dictionary): Dictionary of the metrics for each fold.\n",
    "    \"\"\"\n",
    "    # Initialize lists to store the models and their scores\n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    roc_auc_scores = []\n",
    "    \n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.to_numpy()\n",
    "    if isinstance(y, pd.Series):\n",
    "        y = y.to_numpy()\n",
    "    # Create a StratifiedKFold cross-validation iterator\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=8)\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Fit the estimator on the training data\n",
    "        st = time.time()\n",
    "        model = estimator.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate accuracy and F1 score\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "        # Append the model and its scores to the lists\n",
    "\n",
    "        accuracy_scores.append(accuracy)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        # Calculate ROC AUC score for multi-class classification\n",
    "\n",
    "        # Convert the labels to one-hot encoded format for ROC AUC\n",
    "        y_prob = model.predict_proba(X_test)\n",
    "        \n",
    "        if y_prob.shape[1] != 925: #Break if the model has not predicted at least one of each species class\n",
    "            break\n",
    "        \n",
    "        check_class_probabilities(y_prob)\n",
    "        roc_auc = roc_auc_score(y_test, y_prob, average='macro', multi_class='ovr')\n",
    "        \n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        et = time.time()\n",
    "        elapsed = et-st\n",
    "        print('iteration done', elapsed)\n",
    "        \n",
    "    cv_dict = {'acc': accuracy_scores,\n",
    "            'f1': f1_scores,\n",
    "            'roc-auc': roc_auc_scores}\n",
    "    return model, cv_dict\n",
    "\n",
    "                     \n",
    "def ensemble_cv(X, y, cv=4):\n",
    "    \"\"\"\n",
    "     Specialised function to complete cross validation on an ensemble model. \n",
    "     Returns a dictionary of the accuracy, f1-score, and ROC-AUC score (averaged on a 'one-versus-rest' approach) per fold.\n",
    "    \n",
    "    The function breaks if the model does not predict at least one of each class. \n",
    "    \n",
    "    Parameters:\n",
    "    X (Series): Input data to be used to fit the model.\n",
    "    y (Array): Class data to be used to fit the model.\n",
    "    cv (int): Number of folds. Default is 4.\n",
    "    Returns:\n",
    "    ens (list): Ensemble of the classifiers organised into a list. \n",
    "    cv_dict (Dictionary): Dictionary of the metrics for each fold.\n",
    "    \"\"\"\n",
    "    cv_dict = {'roc-auc': [],\n",
    "               'f1': [],\n",
    "               'acc': []}\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.to_numpy()\n",
    "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=8)\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "        model = RandomForestClassifier(n_estimators=10, max_depth = 15, random_state = 8)\n",
    "        N = 6\n",
    "        ens = []\n",
    "        for i in range(N):\n",
    "            v = model.fit(X_train, y_train)\n",
    "            ens.append(v)\n",
    "            print('iteration done')\n",
    "        \n",
    "        predictions = np.array([clf.predict(X_test) for clf in ens])\n",
    "        final_predictions, _ = mode(predictions, axis=0)\n",
    "        final_predictions = final_predictions.T\n",
    "        final_predictions = final_predictions.reshape(len(final_predictions),)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, final_predictions)\n",
    "        f1 = f1_score(y_test, final_predictions, average='macro')\n",
    "\n",
    "        roc_auc_scores = []\n",
    "        o = {}\n",
    "        y_test_new = y_test-1\n",
    "        classes = np.unique(y_test_new)\n",
    "        for class_label in range(classes[-1]+1):\n",
    "            o[class_label] = []\n",
    "                \n",
    "        for classifier in ens:\n",
    "            \n",
    "            probs =  ens[0].predict_proba(X_test)\n",
    "            if probs.shape[1] != 925:\n",
    "                break\n",
    "            \n",
    "            if len(probs[0]) != len(classes):\n",
    "                fin = classes[-1]\n",
    "                num = fin- len(probs[0])\n",
    "                probs = np.pad(probs, ((0, 0), (0, num+1)), mode='constant', constant_values=0)\n",
    "        \n",
    "        #take classes down by one\n",
    "            \n",
    "            for class_label in range(0,classes[-1]+1):\n",
    "                if class_label in y_test_new:\n",
    "                    # Using the One-versus-rest approach\n",
    "                    y_binary = (y_test_new == class_label).astype(int)\n",
    "                    \n",
    "                    binary_probabilities = probs[:, class_label]\n",
    "                    \n",
    "                    roc_auc = roc_auc_score(y_binary, binary_probabilities)\n",
    "                    roc_auc_scores.append(roc_auc)\n",
    "                    o[class_label].append(roc_auc)\n",
    "                    \n",
    "                else:\n",
    "                    continue\n",
    "            print('metrics done')\n",
    "\n",
    "        means = {}\n",
    "            \n",
    "        # Iterate through the keys and their associated values\n",
    "        for key, values in o.items():\n",
    "            if values:  # Check if the list is not empty\n",
    "                mean = sum(values) / len(values)\n",
    "                means[key] = mean\n",
    "        \n",
    "        roc_auc_final = sum(means.values()) / len(means)\n",
    "        \n",
    "        cv_dict['roc-auc'].append(roc_auc_final)\n",
    "        cv_dict['f1'].append(f1)\n",
    "        cv_dict['acc'].append(accuracy)\n",
    "        \n",
    "        print('fold done')\n",
    "        \n",
    "        \n",
    "    return ens, cv_dict\n",
    "\n",
    "def undersample_importer(df, reduction_percentage):\n",
    "    \"\"\"\n",
    "    An importer function that reduces the dataset by the percentage entered as an argument.\n",
    "    This function also keeps class proportion consistent, just scaled down.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): Input data to be used to fit the model.\n",
    "    reduction_percentage (Float): The percentage to reeduce the dataset by.\n",
    "    Returns:\n",
    "    X (DataFrame): A DataFrame of the input data.\n",
    "    y (Series): A series of the target labels for the species classes.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_list = dfs_in_list()\n",
    "    reduction_percentage = reduction_percentage\n",
    "    \n",
    "    original_class_counts = dict(Counter(comb_df[2]))\n",
    "    reduced_class_counts = {cls: int(count * (1 - reduction_percentage)) for cls, count in original_class_counts.items()}\n",
    "    \n",
    "    undersampled_data = []\n",
    "    for cls in original_class_counts:\n",
    "        class_data = df[df[2] == cls]\n",
    "        num_samples_to_keep = reduced_class_counts[cls]\n",
    "        undersampled_class = resample(class_data, n_samples=num_samples_to_keep, replace=False)\n",
    "        undersampled_data.append(undersampled_class)\n",
    "    \n",
    "    # Combine the undersampled classes\n",
    "    final_dataset = pd.concat(undersampled_data)\n",
    "    \n",
    "    method_names = ['tchebyshev', 'bglbp', 'cslbp', 'cssiltp', 'siltp', 'scslbp', 'olbp']\n",
    "    \n",
    "    att_names = []\n",
    "    \n",
    "    \n",
    "    for i in range(0, len(df_list)):\n",
    "        df = df_list[i]\n",
    "        l = attr_name(df, method_names[i])\n",
    "        att_names.append(l)\n",
    "\n",
    "    X = final_dataset.drop([0,1,2], axis=1)\n",
    "    y = final_dataset[2].values\n",
    "    \n",
    "    att_names_ext = []\n",
    "\n",
    "    # Extend the combined_data list with the elements from each array\n",
    "    for arr in att_names:\n",
    "        att_names_ext.extend(arr)\n",
    "    \n",
    "    X.columns = att_names_ext\n",
    "    \n",
    "    return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fbfb21",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3a9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = dfs_in_list()\n",
    "\n",
    "for df in df_list:\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ff768d",
   "metadata": {},
   "source": [
    "Certain data gathered from different feature extraction methods exemplify greater dimensions than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1725ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combine_df()\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e458103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = find_missing_values(df[2].values)\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da101e37",
   "metadata": {},
   "source": [
    "There is a substantial number of dimensions to this dataset. This may cause significant issues in future models as the working machine has a limited RAM capacity of 16GB.\n",
    "Feature selection will be required. \n",
    "\n",
    "Furthermore, there are missing classes evident in species class. This will need to be adjusted when creating XGBoost models, this model requires the classes to be incremental."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d5e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[2].hist(bins=len(df[2].unique()) , figsize=(35, 15), color='black')\n",
    "plt.title('Distribution of Samples by Species', fontsize=50, alpha=0.75)\n",
    "plt.ylabel('Number of Samples', fontsize=30, alpha=0.75)\n",
    "plt.xlabel('Species Class Label', fontsize=30, alpha=0.75)\n",
    "plt.xticks(rotation=0, fontsize=20, alpha=0.75)\n",
    "plt.yticks(rotation=0, fontsize=20, alpha=0.75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d6031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(df[2], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a739631",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(df[2], return_counts=True)[1].max())\n",
    "print(np.unique(df[2], return_counts=True)[1].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea7a8b5",
   "metadata": {},
   "source": [
    "There is substantial class imbalance present in the species label of the dataset, with the count for the smallest and largest number of samples per species being 11320 and 10 respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cefb333",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0].hist(bins=len(df[0].unique()) , figsize=(35, 15), color='black')\n",
    "plt.title('Distribution of Samples by Family', fontsize=50, alpha=0.75)\n",
    "plt.ylabel('Number of Samples', fontsize=30, alpha=0.75)\n",
    "plt.xlabel('Family Class Label', fontsize=30, alpha=0.75)\n",
    "plt.xticks(rotation=0, fontsize=20, alpha=0.75)\n",
    "plt.yticks(rotation=0, fontsize=20, alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e3909",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(df[0], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9e7223",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(df[0], return_counts=True)[1].max())\n",
    "print(np.unique(df[0], return_counts=True)[1].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f530ed",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff85f9e2",
   "metadata": {},
   "source": [
    "A Decision Tree (DT) will first be trained on the entireity of the merged dataset. No hyperparamters will be tuned it is assumed that the Random Forest (RF) classifier will perform better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4216f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = importer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, stratify = y)\n",
    "model = DecisionTreeClassifier(random_state = 8)\n",
    "model, cv_dict = cross_validate_new(model, X_train, y_train, cv=4)\n",
    "print(cv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf9485",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean(cv_dict['roc-auc']))\n",
    "print(mean(cv_dict['f1']))\n",
    "print(mean(cv_dict['acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fa22e1",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f82a23",
   "metadata": {},
   "source": [
    "A Random Forest (RF) trained on the complete dataset. Default parameters are used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8a915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 50, random_state = 8)\n",
    "model, cv_dict = cross_validate_new(model, X_train, y_train, cv=4)\n",
    "print(cv_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1052713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean(cv_dict['roc-auc']))\n",
    "print(mean(cv_dict['f1']))\n",
    "print(mean(cv_dict['acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b831a4fb",
   "metadata": {},
   "source": [
    "The RF model shows significant improvement in class distinction ability compared to the DT.\n",
    "This model will continue being the object of comparison for future models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d804a7",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e274f94d",
   "metadata": {},
   "source": [
    "Feature selection will be impertive in respect to substantial size of the combined dataset (293830, 536). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af39a706",
   "metadata": {},
   "source": [
    "## RF Per Feature Extraction Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb8d9a3",
   "metadata": {},
   "source": [
    "First, an RF will be trained on the each of the dataset containing different feature extraction methods.\n",
    "This is done to determine if a data obtained from a specific feature extraction method works far more effectively than others in classifying wood species.\n",
    "Doing so will also reduce the model's strain on the computer's memory by reducing dimensionality whilst retaining performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddedb71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = ['tchebyshev', 'bglbp', 'cslbp', 'cssiltp', 'siltp', 'scslbp', 'olbp']\n",
    "\n",
    "for i in range(len(df_list)):\n",
    "    X = df_list[i].drop(columns = [0,1,2])\n",
    "    y = df_list[i][2]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, stratify = y)\n",
    "    model = RandomForestClassifier(n_estimators = 50, random_state = 8)\n",
    "    model, cv_dict = cross_validate_new(model, X_train, y_train, cv=4)\n",
    "    print('#################################################')\n",
    "    print(method_names[i])\n",
    "    print(mean(cv_dict['roc-auc']))\n",
    "    print(mean(cv_dict['f1']))\n",
    "    print(mean(cv_dict['acc']))\n",
    "    print('#################################################')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1b286b",
   "metadata": {},
   "source": [
    "The data obtained throug the OLBP feature extraction method exhibits the best performance, whilst the models fitted on the CSSILTP data produce least effective classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569a1f41",
   "metadata": {},
   "source": [
    "## Feature Selection by Information Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace0d0f2",
   "metadata": {},
   "source": [
    "Next, feature selection can be done on the merged dataset, whereby each feature's importance in information gain is calculated.\n",
    "It is assumed that sampling only the most effective features will generate the best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8b7324",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = importer()\n",
    "\n",
    "info_gain = mutual_info_classif(X,y)\n",
    "method_names = ['tchebyshev', 'bglbp', 'cslbp', 'cssiltp', 'siltp', 'scslbp', 'olbp'] \n",
    "att_names = []\n",
    "\n",
    "for i in range(len(df_list)):\n",
    "    df = df_list[i]\n",
    "    l = attr_name(df, method_names[i])\n",
    "    att_names.append(l)\n",
    "    \n",
    "att_names_ext = []\n",
    "\n",
    "# Extend the combined_data list with the elements from each array\n",
    "for arr in att_names:\n",
    "    att_names_ext.extend(arr)\n",
    "\n",
    "info_gain = pd.DataFrame({'feature': att_names_ext, 'gain': info_gain})\n",
    "info_gain = info_gain.sort_values(by='gain', ascending=False)\n",
    "\n",
    "mini = info_gain[info_gain['gain'] >= info_gain['gain'].mean()]\n",
    "avg = mini.iloc[-1]['feature']\n",
    "\n",
    "\n",
    "ax = sns.barplot(y= \"importance\", x = \"feature\", data = info_gain, palette=(\"mako\"))\n",
    "#ax.set_xticklabels(ax.get_xticklabels(), rotation=45, fontsize=8)\n",
    "ax.set_xlabel(\"Feature\", fontsize=20)  # Adjust the x-label fontsize as needed\n",
    "ax.set_ylabel(\"Importance\", fontsize=20)  # Adjust the y-label fontsize as needed\n",
    "ax.set(xticklabels=[])\n",
    "ax.axvline(x=avg, color='red', linestyle='--')\n",
    "# Set y-tick label font size\n",
    "ax.tick_params(axis='y', labelsize=20)\n",
    "sns.set_context(\"poster\")\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(20, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadc2c2e",
   "metadata": {},
   "source": [
    "Next, RF models are fitted with data that uses the features of differing levels.\n",
    "Specifically, performance of models with features that have an information gain value:\n",
    "- In the 70th percentile of information gain\n",
    "- Greater than the mean of information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7504d5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = importer()\n",
    "\n",
    "info_gain = info_gain[info_gain['importance'] >= 0.7]\n",
    "\n",
    "X = X[info_gain['feature']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, stratify = comb_df[2].values)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 50, random_state=8)\n",
    "model, cv_dict = cross_validate_new(model, X_train, y_train, cv=4)\n",
    "print(mean(cv_dict['roc-auc']))\n",
    "print(mean(cv_dict['f1']))\n",
    "print(mean(cv_dict['acc']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48754cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = importer()\n",
    "\n",
    "info_gain = info_gain[info_gain['importance'] >= info_gain['importance'].mean()]\n",
    "\n",
    "X = X[info_gain['feature']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, stratify = comb_df[2].values)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 50, random_state=8)\n",
    "model, cv_dict = cross_validate_new(model, X_train, y_train, cv=4)\n",
    "print(mean(cv_dict['roc-auc']))\n",
    "print(mean(cv_dict['f1']))\n",
    "print(mean(cv_dict['acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc040864",
   "metadata": {},
   "source": [
    "The RF model fitted using the features that had an information gain value greater than the mean peforms better than using features in the 70th percentile. Furthermore, it also performs better than the RF fitted with the completely merged dataset. \n",
    "Future models will be fitted using data filtered by these features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6a2ffe",
   "metadata": {},
   "source": [
    "# RF Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad28d97",
   "metadata": {},
   "source": [
    "With feature selection completed, next is to determine which machine learning model is most appropriate for the task.\n",
    "The default hyperparameters (100 estimators, maximum depth trees) will been extensive for this task, and will be pruned in the hyperparameter tuning phase to retain performance while being less memory exhaustive. \n",
    "An RF has been used up to this point, and will be further optimised by adjusting for the number of estimators in each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a284787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = importer()\n",
    "info_gain = pd.read_pickle(\"info_gain.pkl\")\n",
    "X = X[info_gain['feature']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, stratify = comb_df[2].values)\n",
    "\n",
    "train_roc_auc_list = []\n",
    "test_roc_auc_list = []\n",
    "estimator_range = range(1, 56, 5)\n",
    "for n_estimators in estimator_range:\n",
    "    rf = RandomForestClassifier(n_estimators = n_estimators)\n",
    "    rf, cv_dict = cross_validate_new(rf, X_train, y_train, cv=4)\n",
    "    print('######################################################')\n",
    "    print(mean(cv_dict['roc-auc']))\n",
    "    print(mean(cv_dict['f1']))\n",
    "    print(mean(cv_dict['acc']))\n",
    "    print('######################################################')\n",
    "    print('iteration done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461fee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,6))\n",
    "plt.plot(list(estimator_range), train_roc_auc_list, color = 'blue', label = 'Training Accuracy per N Estimators')\n",
    "plt.plot(list(estimator_range),test_roc_auc_list, color = 'red', label ='Training Accuracy per N Estimators')\n",
    "plt.xticks(list(estimator_range))\n",
    "#plt.title(dataset + ' Actual vs  Prediction for  Day', fontsize = 20,fontweight = \"bold\")\n",
    "plt.xlabel('Date', fontsize = 18,fontweight = \"bold\")\n",
    "#plt.ylabel(dataset + ' Close Price ($)', fontsize = 18,fontweight = \"bold\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c994e23",
   "metadata": {},
   "source": [
    "The ROC-AUC for an RF stagnates after approximately 25 estimators. Using estimators after this point will cause diminishing returns, as the RF will become significantly larger with each estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aae2077",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_roc_auc_list = []\n",
    "test_roc_auc_list = []\n",
    "depth_range = range(1, 50, 5)\n",
    "for depth in depth_range:\n",
    "    rf = RandomForestClassifier(n_estimators = 25, max_depth = depth)\n",
    "    rf, cv_dict = cross_validate_new(rf, X_train, y_train, cv=4)\n",
    "    print('######################################################')\n",
    "    print(mean(cv_dict['roc-auc']))\n",
    "    print(mean(cv_dict['f1']))\n",
    "    print(mean(cv_dict['acc']))\n",
    "    print('######################################################')\n",
    "    print('iteration done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39283e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,6))\n",
    "plt.plot(list(estimator_range), train_roc_auc_list, color = 'blue', label = 'Training Accuracy per N Depth')\n",
    "plt.plot(list(estimator_range),test_roc_auc_list, color = 'red', label ='Training Accuracy per N Depth')\n",
    "plt.xticks(list(estimator_range))\n",
    "plt.xlabel('Date', fontsize = 18,fontweight = \"bold\")\n",
    "plt.ylabel('N depth', fontsize = 18,fontweight = \"bold\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa5752c",
   "metadata": {},
   "source": [
    "The maximum depth of each tree will be kept constant at 40. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d85f3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 25, max_depth = 40)\n",
    "rf, cv_dict = cross_validate_new(rf, X_train, y_train, cv=4)\n",
    "\n",
    "print(mean(cv_dict['roc-auc']))\n",
    "print(mean(cv_dict['f1']))\n",
    "print(mean(cv_dict['acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e23349",
   "metadata": {},
   "source": [
    "# XGBoost Training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0dd2ed",
   "metadata": {},
   "source": [
    "XGBoost is an extension of Adaboost, of which was immediately assumed to be a weaker classifier in consideration of the high dimensionality and class distribution of the dataset. \n",
    "XGBoost requires incremental class data from 0; when making xgboost = 1 in the importer function, class labels have the missing values removed and the sequence incrementalised so the model can be executed.\n",
    "\n",
    "The XGBoost was fitted to have RF that was consistent with the chosen hyperparameters: number of estimators: 25, max depth of 40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = importer(xgboost = 1)\n",
    "info_gain = pd.read_pickle(\"info_gain.pkl\")\n",
    "\n",
    "X = X[info_gain['feature']]\n",
    "y = y-1 ## Further reduce the sequence to begin from 0\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7437b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y)\n",
    "\n",
    "model = xgb.XGBClassifier(n_estimators = 25, max_depth=40, objective='multi:softmax', \n",
    "                          num_class=len(classes), n_jobs = 5, ## Allow parallelisation across 5 cores of the CPU.\n",
    "                          random_state = 8) \n",
    "\n",
    "model, cv_dict = cross_validate_new(model, X_train, y_train, cv=4)\n",
    "print(mean(cv_dict['roc-auc']))\n",
    "print(mean(cv_dict['f1']))\n",
    "print(mean(cv_dict['acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50ae5ad",
   "metadata": {},
   "source": [
    "There is a significant difference in the metrics across each fold. Due to the hyperparameters being constant across each folds, this large difference across folds suggest that the XGBoost model is sensitive to changes to class distribution in the dataset.\n",
    "As such, when dealing with unknown data in the future, a model exemplifying such characterisitcs would not be used regardless.\n",
    "\n",
    "Despite this, the best performing model is not as effective at classifying compared to the RF model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20252da",
   "metadata": {},
   "source": [
    "Literature suggests that a smaller dataset with smaller distribution of classes will be more effective.\n",
    "Testing this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da478125",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df = combine_df()\n",
    "\n",
    "info_gain = pd.read_pickle(\"info_gain.pkl\")\n",
    "\n",
    "missing_values = find_missing_values(comb_df[2].values)\n",
    "df_fixed = reduce_sequence(missing_values, comb_df)\n",
    "\n",
    "df_fixed = df_fixed[df_fixed[2] <= 50] # Classifying for only the first 50 classes\n",
    "\n",
    "X = df_fixed.drop(columns=[0,1,2])\n",
    "y = df_fixed[2]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6a58af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(n_estimators = 25, max_depth=40, objective='multi:softmax', \n",
    "                          num_class=len(classes), n_jobs = 5, ## Allow parallelisation across 5 cores of the CPU.\n",
    "                          random_state = 8) \n",
    "\n",
    "model, cv_dict = cross_validate_new(model, X_train, y_train, cv=4)\n",
    "print(mean(cv_dict['roc-auc']))\n",
    "print(mean(cv_dict['f1']))\n",
    "print(mean(cv_dict['acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683fa141",
   "metadata": {},
   "source": [
    "Significantly better peformance compared to using the xgboost on the entirety of the dataset.\n",
    "Now to compare against the RF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d47ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=25, max_depth=40, random_state=8)\n",
    "model, cv_dict = cross_validate_new(clf, X_train, y_train, cv=4)\n",
    "print(mean(cv_dict['roc-auc']))\n",
    "print(mean(cv_dict['f1']))\n",
    "print(mean(cv_dict['acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82c434a",
   "metadata": {},
   "source": [
    "No difference; understandable as the smaller dataset can lead both models in determining similar decision boundaries that produce equal results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1ae8ad",
   "metadata": {},
   "source": [
    "# Support Vector Machine Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6303f0",
   "metadata": {},
   "source": [
    "A support vector machine (SVM) model will be conducted on the training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51085fe1",
   "metadata": {},
   "source": [
    "DO NOT RUN BELOW CODE, EXENSIVE AMOUNT OF TIME TO RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7127ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = SVC(kernel=\"poly\", degree=8, C=0.5, probability=True)# Probability set equal to true to return probabilites\n",
    "#model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68cdd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = model.predict(X_test)\n",
    "#probs = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74313cc9",
   "metadata": {},
   "source": [
    "The SVM on the complete dataset even with feature selection took an extended amount of time to complete, with obtaining predictrions taking longer than actually training.\n",
    "To ensure that all models are covered, the data will be undersampled with class distribution maintained. \n",
    "An RF with the optimised parameters will then be run on the undersampled data for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842547af",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df = combine_df()\n",
    "\n",
    "info_gain = pd.read_pickle(\"info_gain.pkl\")\n",
    "\n",
    "## The following was done so as to ensure the ROC-AUC score can be calculated.\n",
    "missing_values = find_missing_values(comb_df[2].values)\n",
    "df_fixed = reduce_sequence(missing_values, comb_df)\n",
    "X, y = undersample_importer(df_fixed, 0.7) # Reduce the dataset by 70%\n",
    "\n",
    "X = X[info_gain['feature']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a389fbc",
   "metadata": {},
   "source": [
    "Using the 'poly' kernal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c39f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel=\"poly\", degree=7, probability=True)\n",
    "model, cv_dict = cross_validate_new(model, X_train, y_train, cv=4)\n",
    "print(mean(cv_dict['roc-auc']))\n",
    "print(mean(cv_dict['f1']))\n",
    "print(mean(cv_dict['acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18e4c85",
   "metadata": {},
   "source": [
    "Using the 'rbf' kernal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9747a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel=\"rbf\", degree=7, probability=True)\n",
    "model, cv_dict = cross_validate_new(model, X_train, y_train, cv=4)\n",
    "print(mean(cv_dict['roc-auc']))\n",
    "print(mean(cv_dict['f1']))\n",
    "print(mean(cv_dict['acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d152635",
   "metadata": {},
   "source": [
    "Using the 'sigmoid' kernal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a6f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel=\"sigmoid\", degree=7, probability=True)\n",
    "model, cv_dict = cross_validate_new(model, X_train, y_train, cv=4)\n",
    "print(mean(cv_dict['roc-auc']))\n",
    "print(mean(cv_dict['f1']))\n",
    "print(mean(cv_dict['acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f7feaf",
   "metadata": {},
   "source": [
    "The 'poly' kernal demonstrates the best ROC-AUC score, and will be used for the future training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8ae7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6,13)\n",
    "    model = SVC(kernel=\"poly\", degree=i, probability=True)\n",
    "    model, cv_dict = cross_validate_new(model, X_train, y_train, cv=4)\n",
    "    print(mean(cv_dict['roc-auc']))\n",
    "    print(mean(cv_dict['f1']))\n",
    "    print(mean(cv_dict['acc']))\n",
    "    print('###############################################')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ec747e",
   "metadata": {},
   "source": [
    "A degree of 10 indicates best ROC-AUC, will be used to compared with the RF below on the undersample dataset. \n",
    "The model exemplifies a high ROC-AUC score, however, demonstrates a poor F1 and accuracy score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8fb85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 25, max_depth = 40, random_state=8)\n",
    "clf, cv_dict = cross_validate_new(clf, X_train, y_train, cv=4)\n",
    "print(mean(cv_dict['roc-auc']))\n",
    "print(mean(cv_dict['f1']))\n",
    "print(mean(cv_dict['acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac9739",
   "metadata": {},
   "source": [
    "RF shows superior performance on the undersampled data, therefore, the SVM will be disregarded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818dcc8d",
   "metadata": {},
   "source": [
    "# RF Ensemble "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba5066a",
   "metadata": {},
   "source": [
    "Now with the model chosen, next to determine if an ensemble of RFs is a more effective at classifying the species of wood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb089b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = importer(xgboost=1) # The classes will be incrementalised to ensure the ROC-AUC score can be calculated. \n",
    "info_gain = pd.read_pickle(\"info_gain.pkl\")\n",
    "\n",
    "X = X[info_gain['feature']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, stratify = y)\n",
    "final_predictions, ens_dict, cv_dict = ensemble_cv(X_train, y_train)\n",
    "print(mean(cv_dict['roc-auc']))\n",
    "print(mean(cv_dict['f1']))\n",
    "print(mean(cv_dict['acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24ae966",
   "metadata": {},
   "source": [
    "An ensemble of RF shows better performance compared to a single RF. This is currently the benchmark model for future training.\n",
    "However, such a model is highly memory exhaustive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd11a5",
   "metadata": {},
   "source": [
    "# Cascade of Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc7a2db",
   "metadata": {},
   "source": [
    "The idea behind this model is based on the assumption that an RF model will be a more effective classifier on a subset of classes. So, if the input data can be effectively classify the input data based on its family, therefore, running the data on a model especially trained on that subset of family's species should be far more accurate.\n",
    "Incorrectly predicting the family in the first layer is offset by greater classification capabilities in the sucessive layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f63776b",
   "metadata": {},
   "source": [
    "## RF on Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c617921e",
   "metadata": {},
   "source": [
    "Prior testing demonstrated that an ensemble of RF are better classifiers compared to a single RF fitted to classify the species label. \n",
    "This will be assumed to be consistent for an ensemble of RF fitted to the family labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8284bf7",
   "metadata": {},
   "source": [
    "## RF on Subset of Species Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a2a400",
   "metadata": {},
   "source": [
    "Next, to determine if an RF will be a more effective classifier on a subset of species labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d745bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df = combine_df()\n",
    "family_list = [1,2,3,4,5,6,7,8,9,10]\n",
    "comb_df = comb_df[comb_df[0].isin(family_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc960c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = comb_df.drop(columns=[0,1,2])\n",
    "y = comb_df[2]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.2, stratify = y)\n",
    "model = RandomForestClassifier(n_estimators = 25, max_depth = 8, random_state=8)\n",
    "model, cv_dict = cross_validate_new(model, X_train, y_train, cv=4)\n",
    "print(mean(cv_dict['roc-auc']))\n",
    "print(mean(cv_dict['f1']))\n",
    "print(mean(cv_dict['acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231f7973",
   "metadata": {},
   "source": [
    "As expected, the RF model trained on a subset of data is a more effective classifier. \n",
    "An ensemble of models can be applied at this layer, however, there would be diminishing returns as the model would substantially large and more computational expensive. We want the initial layer to be as effective as possible, therefore we will make the first layer an ensemble, but the models trained on a subset of families will only be a single RF model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8bb4e3",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c96c12",
   "metadata": {},
   "source": [
    "A class object will be created to construct this cascade of ensemble. An auxilary function will be created to do stratified cross validation on the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0269a211",
   "metadata": {},
   "outputs": [],
   "source": [
    "class wf_ensemble:\n",
    "    def __init__(self, chunks=6):\n",
    "        \"\"\"\n",
    "        Initialisation function for the class. Upon construction, methods are added to the class that will be \n",
    "            filled as training commences.\n",
    "\n",
    "\n",
    "        A dictionary is intialised that splits the dataset into its families and corresponding species.\n",
    "        Ensure that the length of the unique classes in the family column is divisible by the input for chunks, \n",
    "            as each chunk will have an equal number of family classes. Note that this corresponds to the number \n",
    "            of models that will be produced for the species layer. Default is 6.\n",
    "\n",
    "        Parameters:\n",
    "        chunks (int): The number of which the families will be split.\n",
    "\n",
    "        Returns:\n",
    "        self.speDict (Dictionary): Dictionary of each chunk's families and associated species.\n",
    "        \"\"\"\n",
    "        self.chunks = chunks\n",
    "        self.fam_ens = None\n",
    "        self.fam_predictions = None\n",
    "        self.probs = {}\n",
    "        self.roc = {}\n",
    "        self.metrics = {}\n",
    "        self.preds_roc = {}\n",
    "        self.spe_preds = None\n",
    "        comb_df = combine_df()\n",
    "        \n",
    "        comb_df = combine_df()\n",
    "        # Initialize an empty dictionary to store the key-value pairs\n",
    "        speDict = {}\n",
    "        \n",
    "        # Initialize the starting value\n",
    "        current_value = 1\n",
    "        size = len(np.unique(comb_df[0]))//chunks\n",
    "        # Iterate for each of the 6 lists\n",
    "        for i in range(chunks):\n",
    "            sub_list = []  # Initialize an empty list for the current sublist\n",
    "            for _ in range(size):\n",
    "                sub_list.append(current_value)  # Add the current value to the sublist\n",
    "                current_value += 1  # Increment the current value by 1\n",
    "            \n",
    "            speDict[i] = {}\n",
    "            speDict[i]['family'] = sub_list\n",
    "            speDict[i]['species'] = np.unique(comb_df[comb_df[0].isin(sub_list)][2]).tolist()\n",
    "        \n",
    "        self.speDict = speDict\n",
    "\n",
    "    \n",
    "    def fam_fit(self, X_train, y_train_family, n_classifiers = 5):\n",
    "        \"\"\"\n",
    "        The method to train the ensemble of RFs. The target will be family column instead.\n",
    "        \n",
    "        Parameters:\n",
    "        X_train (Series): Input data to be used to fit the model.\n",
    "        y_train_family (Array): Class data to be used to fit the model, for this layer specifically needs to be the family class.\n",
    "        n_classifiers (int): Number of classifiers in the ensemble.\n",
    "        \n",
    "        Returns:\n",
    "        self.fam_ens (list): Ensemble of classifiers trained to determined the family of the input data.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.fam_ens = []\n",
    "        for i in range(n_classifiers):\n",
    "            model = RandomForestClassifier(n_estimators=25, max_depth=40, random_state=8)\n",
    "            model.fit(X_train, y_train_family)\n",
    "            self.fam_ens.append(model)\n",
    "            print('family training iteration done',i)\n",
    "        \n",
    "        \n",
    "    def fam_predict(self, X):\n",
    "        \"\"\"\n",
    "        Generate a predictions from the ensemble using majority vote. \n",
    "        \n",
    "        Parameters:\n",
    "        X (Series): Input data to be used to fit the model. In training, this would be the testing data for X. \n",
    "        \n",
    "        Returns:\n",
    "        self.fam_predictions (array): Predictions for the family of the input data.\n",
    "        \"\"\"\n",
    "        predictions = np.zeros((len(X), len(self.fam_ens)), dtype=int)\n",
    "        # Predict with each classifier\n",
    "        for i, classifier in enumerate(self.fam_ens):\n",
    "            predictions[:, i] = classifier.predict(X)\n",
    "        \n",
    "        # Perform majority voting to get the final predictions\n",
    "        self.fam_predictions = np.apply_along_axis(lambda x: np.argmax(np.bincount(x)), axis=1, arr=predictions).astype(int)\n",
    "            \n",
    "        print('family prediction done')\n",
    "        \n",
    "    def spe_fit(self, X_train, y_train_species, y_train_family):\n",
    "        \"\"\"\n",
    "        The method to train a model for each chunk of families, predicting the species of the input data.\n",
    "        \n",
    "        Parameters:\n",
    "        X_train (Series): Input data to be used to fit the model.\n",
    "        y_train_species (Array): Labels of the species of the input data. \n",
    "        y_train_family (Array): Labels of the family of the input data.\n",
    "       \n",
    "        Returns:\n",
    "        self.speDict_ (estimator): Ensemble of classifiers trained to determined the family of the input data.\n",
    "        \"\"\"\n",
    "        for i in range(self.chunks):\n",
    "                \n",
    "            d = np.where(np.isin(y_train_family, self.speDict[i]['family']))\n",
    "            Xv = X_train.iloc[d[0].tolist()]\n",
    "            \n",
    "            yv = y_train_species[d[0]]\n",
    "            \n",
    "            model_ = RandomForestClassifier(n_estimators=25, max_depth=40, random_state=8)\n",
    "            model_.fit(Xv, yv)\n",
    "            \n",
    "            self.speDict[i]['model'] = model_\n",
    "            print('specie training iteration done')\n",
    "        \n",
    "    \n",
    "    def spe_predict(self, X):\n",
    "        \"\"\"\n",
    "        Generate predictions from the input data to determine the species. \n",
    "        \n",
    "        Parameters:\n",
    "        X (Series): Input data to be used to fit the model. For training, this would be the testing data for X.\n",
    "        \n",
    "        Returns:\n",
    "        self.preds_roc (Array): Predictions for the species of the input data. Done to compute the ROC-AUC score, as the predictions need to correspond to their probability. \n",
    "        self.spe_preds (Array): Predictions for the species of the input data, being filled into its associated index.\n",
    "        self.probs (Array): Probabilities for the predicted class. \n",
    "        \"\"\"\n",
    "\n",
    "        self.spe_preds = np.zeros((len(X)), dtype=int)\n",
    "\n",
    "        for i in range(self.chunks):\n",
    "            \n",
    "            spe_index = np.where(np.isin(self.fam_predictions, self.speDict[i]['family']))\n",
    "            spe_X = X.iloc[spe_index[0].tolist()]\n",
    "        \n",
    "            self.preds_roc[i] = self.speDict[i]['model'].predict(spe_X)\n",
    "\n",
    "            self.spe_preds[spe_index] = self.preds_roc[i]\n",
    "            \n",
    "            self.probs[i] = self.speDict[i]['model'].predict_proba(spe_X)\n",
    "            \n",
    "            print('specie prediction iteration done')\n",
    "    \n",
    "        print('species prediction done')\n",
    "        \n",
    "    def compute_metrics(self, y):\n",
    "        \"\"\"\n",
    "        Compute metrics using the data. Specifically, the accuracy, f1-score, and ROC-AUC score.\n",
    "        The ROC-AUC is computed manually on one-versus-rest approach.\n",
    "        \n",
    "        Parameters:\n",
    "        y (Array): Species labels corresponding to the X input data. For training, this is the test labels.\n",
    "        \n",
    "        Returns:\n",
    "        self.metrics (Dictionary): A dictionary for the metrics calculated from the model. Each key corresponds to the metric.\n",
    "        \"\"\"\n",
    "        \n",
    "        acc = accuracy_score(y, self.spe_preds)\n",
    "        f1 = f1_score(y, self.spe_preds, average='macro')\n",
    "        \n",
    "    \n",
    "        for i in range(6):\n",
    "            print(i)\n",
    "            z = self.spe_preds[np.where(np.isin(self.spe_preds, self.speDict[i]['species']))]\n",
    "            \n",
    "            o = {}\n",
    "            for u in self.speDict[i]['species']:\n",
    "                o[f'{u}'] = []\n",
    "            \n",
    "            classes = np.unique(self.speDict[i]['species'])\n",
    "            \n",
    "            \n",
    "            roc_auc_scores = []\n",
    "            \n",
    "            for q in range(len(self.speDict[i]['species'])):\n",
    "                if classes[q] in np.unique(z):\n",
    "                    y_true = (self.preds_roc[i] == classes[q]).astype(int)  # Convert to binary for the current class\n",
    "                    y_scores =  self.probs[i][:, q]\n",
    "                    roc_auc = roc_auc_score(y_true, y_scores)\n",
    "                    o[f'{classes[q]}'] = roc_auc\n",
    "                else:\n",
    "                    o[f'{classes[q]}'] = 0.5\n",
    "        \n",
    "            \n",
    "            \n",
    "            self.roc[i] = o\n",
    "            \n",
    "        total_sum = 0\n",
    "        total_count = 0\n",
    "        \n",
    "    \n",
    "        for sub_dict in self.roc.values():\n",
    "            for value in sub_dict.values():\n",
    "                total_sum += value\n",
    "                total_count += 1\n",
    "        \n",
    "        # Calculate the average\n",
    "        roc_average = total_sum / total_count\n",
    "        \n",
    "        self.metrics['acc'] = acc\n",
    "        self.metrics['f1'] = f1\n",
    "        self.metrics['roc-auc'] = roc_average\n",
    "\n",
    "\n",
    "def cross_validate_wf_ens(info_gain, cv=4):\n",
    "    \"\"\"\n",
    "    Specialised function to complete cross validation on the cascading ensemble model. \n",
    "    \n",
    "    Parameters:\n",
    "    info_gain (DataFrame): The DataFrame of features to filter the dataset by. \n",
    "    cv (int): Number of folds. Default is 4.\n",
    "    \n",
    "    Returns:\n",
    "    wf_ens (class object): The cascading ensemble model constructed as a class object. \n",
    "    cv_dict (Dictionary): Dictionary of the metrics for each fold.\n",
    "    \"\"\"\n",
    "    # Initialize lists to store the models and their scores\n",
    "    X, y_family = importer(family=1)\n",
    "    X, y_species = importer()\n",
    "    \n",
    "    X = X[info_gain['feature']]\n",
    "    e = X.columns.to_list()\n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    roc_auc_scores = []\n",
    "    \n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.to_numpy()\n",
    "\n",
    "    # Create a StratifiedKFold cross-validation iterator\n",
    "    print('import done')\n",
    "    skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=8)\n",
    "\n",
    "    for train_index, test_index in skf.split(X, y_family):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train_family, y_test_family = y_family[train_index], y_family[test_index]\n",
    "        y_train_species, y_test_species = y_species[train_index], y_species[test_index]\n",
    "        \n",
    "        \n",
    "        X_train, X_test = pd.DataFrame(X_train), pd.DataFrame(X_test)\n",
    "\n",
    "        X_train.columns = e\n",
    "        X_test.columns = e\n",
    "        \n",
    "        X_train = X_train[info_gain['feature']]\n",
    "        \n",
    "        wf_ens = wf_ensemble(chunks = 6)\n",
    "    \n",
    "\n",
    "        wf_ens.fam_fit(X_train, y_train_family, 3)\n",
    "        wf_ens.fam_predict(X_test)\n",
    "        \n",
    "        \n",
    "        #X_train = pd.DataFrame(X_train)\n",
    "        wf_ens.spe_fit(X_train, y_train_family, y_train_species)\n",
    "        \n",
    "        for i in range(wf_ens.chunks):\n",
    "            print(wf_ens.speDict[i]['model'].n_classes_)\n",
    "        \n",
    "        #X_test = pd.DataFrame(X_test)\n",
    "        wf_ens.spe_predict(X_test)\n",
    "        \n",
    "        \n",
    "        wf_ens.compute_metrics(X_test, y_test_species)\n",
    "        wf_ens.metrics\n",
    "\n",
    "        accuracy_scores.append(wf_ens.metrics['acc'])\n",
    "        f1_scores.append(wf_ens.metrics['f1'])\n",
    "\n",
    "        roc_auc_scores.append(wf_ens.metrics['roc-auc'])\n",
    "        print('fold done')\n",
    "        \n",
    "    cv_dict = {'acc': accuracy_scores,\n",
    "            'f1': f1_scores,\n",
    "            'roc-auc': roc_auc_scores}\n",
    "    \n",
    "        \n",
    "    return wf_ens, cv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66f28c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_gain = pd.read_pickle(\"info_gain.pkl\")\n",
    "\n",
    "wf_ens, cv_dict = cross_validate_wf_ens()\n",
    "print(mean(cv_dict['roc-auc']))\n",
    "print(mean(cv_dict['f1']))\n",
    "print(mean(cv_dict['acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c7a8bf",
   "metadata": {},
   "source": [
    "The results show that this is the best performing model. No further training is required as the RF have been optimised.\n",
    "Next, to test the model on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d960ba43",
   "metadata": {},
   "source": [
    "## Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61764a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = importer()\n",
    "info_gain = pd.read_pickle(\"info_gain.pkl\")\n",
    "\n",
    "X = X[info_gain['feature']] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=8, test_size=0.2, stratify = y)\n",
    "\n",
    "wf_ens, cv_dict = cross_validate_wf_ens()\n",
    "print(mean(cv_dict['roc-auc']))\n",
    "print(mean(cv_dict['f1']))\n",
    "print(mean(cv_dict['acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d27d07",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc125f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "wf_ens.fam_predict(X)\n",
    "wf_ens.spe_predict(X)\n",
    "wf_ens.compute_metrics(y)\n",
    "ed = time.time()\n",
    "elapsed_time = ed - st\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca69d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_ens.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5266891",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5b4728",
   "metadata": {},
   "source": [
    "Due to the number of classes, the confusion matrix will be filtered down to only display the classes with the lowest associated ROC-AUC values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e167ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the worst performing keys for each sub-dictionary\n",
    "worst_keys = {}\n",
    "\n",
    "# Define the number of worst keys to retrieve\n",
    "num_worst_keys = 8\n",
    "\n",
    "# Iterate through the main dictionary\n",
    "for sub_dict_name, sub_dict in wf_ens.roc.items():\n",
    "    # Filter out keys with a value of 1\n",
    "    filtered_dict = {key: value for key, value in sub_dict.items() if value != 1}\n",
    "    \n",
    "    # Find the worst performing keys from the filtered dictionary\n",
    "    worst_keys[sub_dict_name] = sorted(filtered_dict, key=filtered_dict.get)[:num_worst_keys]\n",
    "\n",
    "\n",
    "combined_list = [item for sublist in worst_keys.values() for item in sublist]\n",
    "combined_list = [int(item) for item in combined_list]\n",
    "\n",
    "confusion_matrix_worst = confusion_matrix(y_test, wf_ens.spe_preds, labels=combined_list[:10])\n",
    "\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix_worst, display_labels = combined_list[:10])\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5e5e7a",
   "metadata": {},
   "source": [
    "## Misclassified Classes in Bar Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cf5012",
   "metadata": {},
   "source": [
    "The confusion matrix was not effective in displaying the misclassified classes.\n",
    "Instead, a bar graph will be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3de51ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y, wf_ens.spe_preds)\n",
    "\n",
    "misclassification_percentage = 1 - np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "\n",
    "threshold = 0.05\n",
    "filtered_indices = np.where(misclassification_percentage >= threshold)[0]\n",
    "\n",
    "bar_width = 0.8  \n",
    "spacing_factor = 1.5  \n",
    "\n",
    "bar_positions = np.arange(len(filtered_indices)) * spacing_factor\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(bar_positions, misclassification_percentage[filtered_indices] * 100, width=bar_width, align=\"center\")\n",
    "plt.xticks(bar_positions, filtered_indices, rotation=45, ha=\"right\")  \n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Misclassification Percentage (%)\")\n",
    "plt.title(f\"Misclassification Percentage by Class (Threshold >= {threshold * 100}%)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddc2afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "misclassification_count = misclassification_percentage[filtered_indices] * np.sum(conf_matrix[filtered_indices], axis=1)\n",
    "\n",
    "bar_width = 0.8 \n",
    "spacing_factor = 1.5 \n",
    "\n",
    "bar_positions = np.arange(len(filtered_indices)) * spacing_factor\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(bar_positions, misclassification_count, width=bar_width, align=\"center\")\n",
    "plt.xticks(bar_positions, filtered_indices, rotation=45, ha=\"right\") \n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Misclassification Count\")\n",
    "plt.title(f\"Misclassification Count by Class (Threshold >= {threshold * 100}%)\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
